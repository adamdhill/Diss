The first three empirical Chapters of the dissertation elucidate key new insights into the contemporary political process. The final Chapter of the dissertation then incorporates those insights into a revised conception of electoral accountability, which I refer to as Contemporary Electoral Accountability ("CEA").^[CEA does not directly compete with Traditional EA. CEA is, by design, more concrete than Traditional EA. If CEA is incompatible with Traditional EA, then it is incumbent upon advocates of Traditional EA to update the theory.]



# The normative problem created by these changes

Traditional EA abstracts away each of these issues. In theory, Traditional EA should be robust enough to handle each of these scenarios. These scenarios should raise mere "implementation details." However, once you remove the assumption that the administrative state is an agent of Congress, the logic of Traditional EA electoral accountability falls apart. Recall, the problem for citizens is to design a system such that incumbents are sufficiently incentivized to act in the public interest. This is a special version of the more general principal-agent problem. [@Manin1999, p. 41] Yet if those making a substantial fraction of policy are not, in fact, the citizens' agents, there is no mechanism of control.


# Normative updates to traditional electoral accountability

It updates the traditional study of electoral accountability in two primary ways. Empirically, it reflects substantive changes in the institutional environments that surround the process of lawmaking. Normatively, contemporary EA takes a broader approach to legitimating the relationship between government and citizens. Recall, the empirical structure of the mechanism design is driven by background normative concerns. The growth of the administrative state necessitates a broader approach to accountability. Limiting accountability merely to elected representatives leaves a vast swath of political power unattended to.

Traditional EA explains the normative significance of the agency relationship between representatives and citizens. But the relationship between citizens and the rest of government is not explained. Some Traditional EA theorists have sought to incorporate an account of the administrative state into Traditional EA. These accounts treat the bureaucracy as agents of elected representatives. These accounts, however, assume that bureaucracies operate like an assembly line.^[See also [@Christiano2005]] In fact, agencies wield discretion to such a degree that they are not appropriately characterized as agents of elected representatives. [@Stewart1975]

We can put the point more forcefully. The breadth of policymaking that happens outside of Congress undercuts the claim that Traditional EA makes about legitimating power relationships. Traditional EA does not explain how voter preferences are transmitted to agencies that create policy. This deficiency undermines the purpose of the Traditional EA account.

Contemporary EA seeks to reinvigorate the normative force of the electoral mechanism. Rather than abstracting away the administrative state, it confronts it directly, and incorporates its role in its theory of electoral accountability. FORMALIZING KAGAN'S PRESIDENTIAL ADMINISTRATION.

# What we know about voters

The approach taken here, like the Traditional account, assumes the worst about elected officials. This assumption is important because the mechanism does not depend on the quality of officials.^[Compare Caselli and Morelli, considering the possibility that voters elect low-quality candidates. [@Caselli2004]] But what about the competence of voters? V.O. Key famously declared the voter to be the "rational god of vengeance and reward."[@Key1964, p. 568] Generations of scholars have tested that claim. Most famously, perhaps, the "Michigan School" argued that voters lack both information and competence. [@Malhotra2013] We are, by now, painfully familiar with data showing that voters lack what appear to be certain forms of crucial information. "Two of the most robust findings about American voters," Bendor et al. summarize, "are that few of them have coherent, detailed ideologies and few know much about politics." [@Bendor2011, p. 109]  As Arthur Lupia writes:

When it comes to political information, there are two groups of people. One group understands that they are almost completely ignorance of almost every detail of almost every law and policy under which they live. The other group is delusional about how much they know. There is no third group. [@Lupia2015, p. 3]

Some have sought to make a virtue of this ignorance. Fiorina argues that voters only need the most modest information about the economy to make electoral accountability work. [@Fiorina1982] Arthur Lupia argues that voters are rationally uninformed. It makes more sense, Lupia argues, for voters to simply take cues from party elites. [@Lupia1994]

Others take a more pessimistic view of the situation. Some argue many citizens - those ignorant of certain facts - have a moral obligation not to vote. Others, citing "the depth of ignorance demonstrated by modern mass publics," go further. [@Bendor2011, p. 109] Democracy, Jason Brennan argues, is "the rule of the ignorant and the irrational, and it too often falls short." [@Brennan2016] Instead, we should be subject to the "rule of the knowledgeable." *Id.*

These debates have persisted for a long time, and quite frankly it's hard to see much progress being made. Wading into debates about voter competence is unlikely to produce new insights. Is it possible to advance a theory of electoral accountability while avoiding  these debates?

# An ongoing conversation

Mechanism design typically operates by identifying one problem, and identifying a fix for it. But, often, the solution can generate a *new* problem. By and large, mechanism designers have not tended to investigate these new problems that arise from their fixes. This dissertation does investigate these problems, and, what's more, it offers solutions to fix them. Of course, these solutions might *themselves* cause fresh problems. In this sense, the ideas presented here represent a part of an ongoing conversation about how to best accomplish democratic accountability, not a perfect solution.


# The four quadrants of mechanism design

Thus far we have treated mechanisms as institutions "designed" by scholars or policymakers. In fact, this is a simplification of a more complex reality. Some mechanisms are, in fact, designed from scratch by identifying a desired outcome and then seeking to create institutions that achieve that goal. For example, Eric Posner and E. Glen Weyl have been recently developing a voting procedure that, they argue, puts the appropriate value on strength of preference. This procedure, which they call Quadratic Voting, derives from already existing "weighted voting" procedures; the Posner and Weyl proposal, however, iterates on existing procedures by formalizing a system for individuals to buy votes. [@Weyl2014] Posner and Weyl acknolwedge the political infeasibility of such a system, an admission which highlights the extent to which it departs from convention.

Alternatively, mechanism design my proceed by identifying real-world institutions and interpreting those institutions as a product of rational choices by their designers. [@Borgers2015] This type of mechanism design treats the institution under discussion *as though* it were created from scratch, and designed to achieve a stipulated set of values. Traditional EA is this latter type of mechanism design. It identifies a real-world institution (an electoral procedure) and interprets it as the product of a rational design intended to achieve legitimate political arrangements, assuming a social contract theory of political power. As we saw in the previous section, Traditional EA explains elections as institutions designed to transmit the preferences of discrete individuals to public policy. This outcome -- i.e., the existence of a principal-agent relationship -- is (taken to be) normatively valuable because it legitimates the rule of agent-representatives.^[Writers in the purely normative tradition have not always appreciated this relationship. Beitz, for example, argues that Downs' theory of spatial party competition is somehow covertly normative. In fact, Downs, and others in this tradition, are fully transparent about the normative underpinnings of their work. See [@Beitz1989, p. 182]]

Mechanism designs also vary along another axis: the degree to which they offer abstract or concerete solutions. [@Maskin2002] Abstract mechanisms seek to be robust against as many implementation details as possible. They seek high levels of fault tolerance. *Id.* Concrete approaches, by contrast, make more assumptions. Typically, abstract theories advance first, and then concrete theories follow in their wake. *Id.*

These two axes produce the graph in Figure 1. The bottom right quadrant represents highly abstract, new ideas. The upper left quandrant, by contrast, represents highly concrete, existing institutions.

These positions do not represent opposing approaches. In theory, a complete understanding of the phenomenon should allow for each point on the graph to be occupied by a slightly different account. In practice, our understanding progresses through a dialogue between different quadrants.^[For example, Maskin argues that "since so much has now been accomplished toward developing implementation theory at a general level, future efforts are likely to concentrate more on concrete applications of the theory, e.g., to contracts or to externalities. Another direction in which we expect the literature to develop is that of bounded rationality." [@Maskin2002, p. 282]]


Strategies for Maximizing Information while Sustaining Effectiveness
Approach 1 --- No Transparency

First, contra Kagan, one might deny the need to hold government accountable for nudges because nudges are not coercive. On this view, the primary goal of accountability is to constrain regulators from unjustifiably materially disadvantaging certain interests (for example, violating principles of cost-benefit analysis) or paternalistically interfering with free choice. \citep{Grant2005} Nudges, however, are often described as achieving regulatory goals without imposing material incentives. For example, Sunstein and Thaler sometimes argue that soft paternalist intervention[s] must not impose significant material incentives.'' \citep[p. 2][Sunstein.draft.2014b] Unlike \emph{hard} paternalism, which imposes incentives by regulatory interventions like taxation, \emph{soft} paternalism at most \emph{immaterially} imposes incentives. One might argue that the performance of a regulatory tool that does not coerce ought not to be taxed by accountability concerns. On this view, accountability (and thus transparency) is a price that a regulatory tool pays for coercing individuals. If a tool operates absent coercion, the need for accountability --- and consequently the need for transparency --- diminishes. However, as Robert Sugden argues,[r]ealistically, the application of libertarian paternalism will involve trade-offs between the welfare gains resulting from the reduction of errors in decision-making and the costs that result from restrictions on choice.'' \citep[p. 369]{Sugden2009b} Nudges in practice do ``significantly obstruct'' individual choice. \citep[3]{Sugden2009b} Nudges make non-preferred outcomes \emph{cognitively} more expensive.\footnote{Overriding a default setting, for example, takes time and cognitive energy. That's the very point of the default. Pointing out that some choice architecture might well justify the imposition of the most beneficial architecture -- but it does diminish the conclusion that all architectures impose costs.} The nature of the coercion might be different from hard paternalism, but soft paternalism nonetheless coerces individuals.

Alternatively, one might deny the need to hold government accountable for nudges because nudges are align with higher order'' (orauthentic'') individual choices. On this view, one can allow that nudges coerce, but insist that this type of coercion --- unlike the coercion characteristic of hard paternalism --- does not impede individual autonomy. Just the opposite, in fact: nudges help individuals achieve autonomy. If nudges help individuals act on their higher order desires, then perhaps lack of accountability is less of a concern. Empirical results, however, do not appear to support this argument. In a study of the acceptability of covert versus overt nudges, Felsen et al. consider the argument that covertly influencing decision processes such that the resulting decision is aligned with higher-order desires may actually enhance autonomy ... .'' \citep[p. 5]{Felsen2013} The results of their study did not support this argument, however.[O]verall we found support for our hypothesis that overt, rather than covert, influences'' are more acceptable. [@Felsen2013, p. 5]

ADD ZWYICKI CITE TO SHOW CONCERN WITH THIS APPROACH
Approach 2 -- Targeted Transparency

If the very need for accountability cannot be reject, then it seems likely that nudges will need to be transparent in some measure. The question becomes how to balance the accountability-enhancing effects of transparency with the possibility that some types of transparency might decrease the the effectiveness of some nudges. One strategy, proposed by Sunstein and Thaler, is to make nudges entirely transparent at the wholesale level, but limit their transparency at the retail level. The hope here is that targeted transparency will retain the performance gains of nudges while allowing \emph{enough} transparency to produce accountability.

Nudges seek to take advantage of biases individuals' decision-making processes --- such as loss aversion, over-confidence, status quo bias, framing, and the tendency toward inertia [@Welch2010, p. 125-26] --- to produce socially optimal outcomes. Thus nudges that affect unconscious processing'' are not promulgated directly to their addressee. \citep[p. 3]{Sunstein2014}; Rather, because the nudge exploits a decision-making bias, they arecovert''. [@Sunstein2014, p. 3] Regulators deploying nudges influence behavior by altering the environment in which individuals make choices. However, if users experience an awareness of being nudged, then there is a risk that at least some users will ``override'' the nudge. Users might correct against the bias that the nudge is seeking to exploit.

Thus, under targeted transparency, information about nudges is freely and openly disseminated among the political class -- agency officials, courts, journalists, and academics --- and anyone interested enough to incur the costs of obtaining relevant analyses. Crucially, however, information about the nudge is not explicitly disclosed to individuals making decisions within a regulated choice environment.

``In its simplest form, the publicity principle bans governments from selecting a policy that it would not be able or willing to defend publicly to its own citizens.'' [@Sunstein2008, p. 244]
Approach 3 --- Full Transparency

Finally, institutional designers might question the assumption that the performance gains associated with nudges depend on lack of transparency to the user. Loewenstein et al. test whether full disclosure can potentially be achieved with little or no negative impact on the effectiveness of the intervention.'' [@Loewenstein2014, p. 2] The study compared the effectiveness of a medical default under conditions where some participants were explicitly informed of the intervention. Loewenstein et al. conclude that theirfindings suggest that the effectiveness of nudges may not depend on deceiving those who are being nudged,'' which would imply that ``policymakers can satisfy the strong form of the transparency advocated in the House of Lords report, with little diminution in the impact of interventions.'' [@Loewenstein2014, p. 13]

To this point, most of the attention paid to soft paternalism has focused on its efficiency and effectiveness. Much less attention has been paid to the unique accountability problems posed by soft paternalism. 
